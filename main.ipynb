{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import skimage\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation,LSTM,TimeDistributed,UpSampling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Input,Reshape,AveragePooling2D,Conv2DTranspose\n",
    "from keras.models import Model, Sequential\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, filters,measure\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300285      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0   6915]\n"
     ]
    }
   ],
   "source": [
    "from skimage import io, filters,measure\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "path=\"/home/p287103/SR/bees/\"\n",
    "# im = io.imread('imbee/beeType1_009.jpg', as_gray=True)\n",
    "im = io.imread(path+'gt-dots/dots009.png', as_gray=True)\n",
    "# plt.imshow(im)\n",
    "val = filters.threshold_sauvola(im)\n",
    "drops = ndimage.binary_fill_holes(im < val)\n",
    "d=ndimage.morphology.binary_dilation(im,iterations=10)\n",
    "# io.imsave('gt/1.png',d\n",
    "im=io.imread('gt/dots011.png')\n",
    "plt.imshow(im)\n",
    "# dd=ndimage.morphology.binary_dilation(d)\n",
    "# plt.imshow(d,cmap='gray')\n",
    "# plt.imshow(drops, cmap='gray')\n",
    "# plt.show()\n",
    "# labels = measure.label(d)\n",
    "# print(labels.max())\n",
    "# print((np.asarray(drops/255.)))\n",
    "# print((d/255.).sum())\n",
    "# print(drops)\n",
    "\n",
    "# im=Image.open('gt/1.png')\n",
    "# im=im.convert('1')\n",
    "# im.save('gt/2.png')\n",
    "# print(im)\n",
    "histo=ndimage.measurements.histogram(im,0,1,256)\n",
    "print(histo)\n",
    "# im=io.imread('gt/1.png')\n",
    "# # print(d)\n",
    "# dd=np.where(im>0.1,im,1)\n",
    "# print(dd)\n",
    "# plt.imshow(dd ,cmap='gray')\n",
    "# # plt.imshow(im)\n",
    "# labels = measure.label(im)\n",
    "# print(labels.max())\n",
    "# print(im)\n",
    "# print((im).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8355161b50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path='/home/p287103/SR/bees'\n",
    "name = (os.listdir(path+'/gt-dots'))\n",
    "# print(name)\n",
    "\n",
    "\n",
    "for text in name:\n",
    "    fullpath=path+\"/gt-dots/\"+text\n",
    "    im = io.imread(fullpath)\n",
    "#     val = filters.threshold_sauvola(im)\n",
    "    # d=ndimage.morphology.binary_dilation(val)\n",
    "    drops = ndimage.binary_opening(im)\n",
    "    io.imsave(path+\"/gt1/\"+text, drops)\n",
    "    # plt.imshow(val)\n",
    "#     plt.imshow(drops, cmap='gray')\n",
    "#     plt.show()\n",
    "#     labels = measure.label(drops)\n",
    "#     print(labels.max())\n",
    "im=io.imread(path+\"/gt1/\"+text)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0729 13:53:20.273051 139821828888320 deprecation_wrapper.py:119] From /home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0729 13:53:20.306052 139821828888320 deprecation_wrapper.py:119] From /home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y=240,320\n",
    "inChannel=3\n",
    "input_img = Input(shape = (x, y, inChannel))\n",
    "batch_size=5\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/ipykernel_launcher.py:22: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "/home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/ipykernel_launcher.py:42: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total image is ..236\n"
     ]
    }
   ],
   "source": [
    "# paths=\"/home/p287103/SR/bees\"\n",
    "# name = (os.listdir(paths))\n",
    "\n",
    "# print(name)\n",
    "# print(paths)\n",
    "valid_exts=[\".pgm\"]\n",
    "labels = []\n",
    "imgcnt=0\n",
    "vec=[]\n",
    "imvec=[]\n",
    "labelvec=[]\n",
    "mylist=[]\n",
    "numbervec=[]\n",
    "maxwordlen=12\n",
    "\n",
    "path=\"/home/p287103/SR/bees/imbee\"\n",
    "name = sorted(os.listdir(path))\n",
    "for text in name:\n",
    "#     print(text)\n",
    "    fullpath=path+\"/\"+text\n",
    "#     print(fullpath)\n",
    "    currimg=imread(fullpath)\n",
    "#     if currimg.ndim==3:\n",
    "#         currimg=currimg[:,:,1]\n",
    "        \n",
    "    graysmall=imresize(currimg,[x,y])\n",
    "    imvec.append(graysmall)\n",
    "    imgcnt=imgcnt+1\n",
    "\n",
    "path=\"/home/p287103/SR/bees/gt\"\n",
    "name = sorted(os.listdir(path))\n",
    "# print(name)\n",
    "\n",
    "for text in name:\n",
    "#     print(text)\n",
    "    fullpath=path+\"/\"+text\n",
    "    currimg=imread(fullpath)\n",
    "#     if currimg.ndim==3:\n",
    "#         currimg=currimg[:,:,1]\n",
    "#     val = filters.threshold_sauvola(im)\n",
    "#     drops = np.asarray(ndimage.binary_fill_holes(im < val))\n",
    "    graysmall=imresize(currimg,[x,y])\n",
    "    graysmall=ndimage.binary_opening(graysmall)\n",
    "    labelvec.append(graysmall)\n",
    "    imgcnt=imgcnt+1\n",
    "  \n",
    "    \n",
    "print(\"number of total image is ..%d\" % (imgcnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 240, 320)\n"
     ]
    }
   ],
   "source": [
    "datasize=118\n",
    "batch_xs=np.asarray(imvec)\n",
    "batch_ys=np.asarray(labelvec)\n",
    "print(batch_ys.shape)\n",
    "X_train=batch_xs.reshape(datasize,x, y, inChannel)\n",
    "Y_train=batch_ys.reshape(datasize,x, y, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# K.teano_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12279833540316989728\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17152487647948247926\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7906218373190830465\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7268886119\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8661022270429311483\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "labels = measure.label(drops)\n",
    "print(labels.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add((AveragePooling2D(pool_size=(1,1))))\n",
    "model.add((Conv2D(16, kernel_size=(7,7),\n",
    "                 activation='relu',\n",
    "                 input_shape=(75,135,1))))\n",
    "#                  input_shape=(43,78,1))))\n",
    "model.add((MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add((Conv2D(32, (5,5), activation='relu')))\n",
    "model.add((MaxPooling2D(pool_size=(2, 2))))\n",
    "# model1 = Sequential()\n",
    "model.add((Conv2DTranspose(\n",
    "              filters=64,\n",
    "              kernel_size=3,\n",
    "              strides=(2, 2),\n",
    "              padding=\"SAME\",\n",
    "              activation='relu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(input_img):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(16, (5,5), activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(32, (5,5), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "#     conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "#     conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "#     pool4 = MaxPooling2D(pool_size=(2, 2))(conv4) #7 x 7 x 64\n",
    "\n",
    "    #decoder\n",
    "#     conv5 = Conv2D(256,(3,3), activation='relu', padding='same')(pool4) #7 x 7 x 128\n",
    "#     up1 = UpSampling2D((2,2))(conv5) # 14 x 14 x 128\n",
    "    conv6 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv2) #7 x 7 x 128\n",
    "    up2= UpSampling2D((2,2))(conv6) # 14 x 14 x 128\n",
    "#     conv7 = Conv2D(16 ,(5,5), activation='relu', padding='same')(up2) # 14 x 14 x 64\n",
    "#     up3= UpSampling2D((2,2))(cozv7) # 28 x 28 x 64\n",
    "    decoded = Conv2D(1, (5,5), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0729 13:53:35.457967 139821828888320 deprecation_wrapper.py:119] From /home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0729 13:53:35.487289 139821828888320 deprecation_wrapper.py:119] From /home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0729 13:53:35.514487 139821828888320 deprecation_wrapper.py:119] From /home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0729 13:53:35.526667 139821828888320 deprecation_wrapper.py:119] From /home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0729 13:53:35.541750 139821828888320 deprecation_wrapper.py:119] From /home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0729 13:53:35.546904 139821828888320 deprecation.py:323] From /home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(input_img, autoencoder(input_img))\n",
    "autoencoder.compile(loss='binary_crossentropy', optimizer = 'adadelta')\n",
    "# autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())\n",
    "# autoencoder.compile(loss='binary_crossentropy', optimizer = RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 240, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 240, 320, 16)      1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 120, 160, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 120, 160, 32)      12832     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 120, 160, 16)      4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 240, 320, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 240, 320, 1)       401       \n",
      "=================================================================\n",
      "Total params: 19,073\n",
      "Trainable params: 19,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0729 13:53:40.591530 139821828888320 deprecation_wrapper.py:119] From /home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "118/118 [==============================] - 13s 113ms/step - loss: 0.6971\n",
      "Epoch 2/500\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.3566\n",
      "Epoch 3/500\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.3564\n",
      "Epoch 4/500\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.3562\n",
      "Epoch 5/500\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.3543\n",
      "Epoch 6/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3564\n",
      "Epoch 7/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.8393\n",
      "Epoch 8/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3568\n",
      "Epoch 9/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3567\n",
      "Epoch 10/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3567\n",
      "Epoch 11/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3566\n",
      "Epoch 12/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3551\n",
      "Epoch 13/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3426\n",
      "Epoch 14/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3371\n",
      "Epoch 15/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3057\n",
      "Epoch 16/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0686\n",
      "Epoch 17/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0472\n",
      "Epoch 18/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0439\n",
      "Epoch 19/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0434\n",
      "Epoch 20/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0407\n",
      "Epoch 21/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0402\n",
      "Epoch 22/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0382\n",
      "Epoch 23/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0490\n",
      "Epoch 24/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0329\n",
      "Epoch 25/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0319\n",
      "Epoch 26/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0344\n",
      "Epoch 27/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0340\n",
      "Epoch 28/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0330\n",
      "Epoch 29/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0333\n",
      "Epoch 30/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0297\n",
      "Epoch 31/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0770\n",
      "Epoch 32/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0324\n",
      "Epoch 33/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0302\n",
      "Epoch 34/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0291\n",
      "Epoch 35/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0292\n",
      "Epoch 36/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0292\n",
      "Epoch 37/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0293\n",
      "Epoch 38/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0487\n",
      "Epoch 39/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0279\n",
      "Epoch 40/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0277\n",
      "Epoch 41/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0281\n",
      "Epoch 42/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0284\n",
      "Epoch 43/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1640\n",
      "Epoch 44/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0748\n",
      "Epoch 45/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0340\n",
      "Epoch 46/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0326\n",
      "Epoch 47/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0314\n",
      "Epoch 48/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0323\n",
      "Epoch 49/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0300\n",
      "Epoch 50/500\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.0291\n",
      "Epoch 51/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0289\n",
      "Epoch 52/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0280\n",
      "Epoch 53/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0286\n",
      "Epoch 54/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0281\n",
      "Epoch 55/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0297\n",
      "Epoch 56/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0273\n",
      "Epoch 57/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0265\n",
      "Epoch 58/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0279\n",
      "Epoch 59/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0270\n",
      "Epoch 60/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0268\n",
      "Epoch 61/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0267\n",
      "Epoch 62/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0262\n",
      "Epoch 63/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0870\n",
      "Epoch 64/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0284\n",
      "Epoch 65/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0265\n",
      "Epoch 66/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0261\n",
      "Epoch 67/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0258\n",
      "Epoch 68/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0261\n",
      "Epoch 69/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0273\n",
      "Epoch 70/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0270\n",
      "Epoch 71/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0270\n",
      "Epoch 72/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0248\n",
      "Epoch 73/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0278\n",
      "Epoch 74/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0258\n",
      "Epoch 75/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0248\n",
      "Epoch 76/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0253\n",
      "Epoch 77/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0250\n",
      "Epoch 78/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0424\n",
      "Epoch 79/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0643\n",
      "Epoch 80/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0255\n",
      "Epoch 81/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0251\n",
      "Epoch 82/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0247\n",
      "Epoch 83/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0246\n",
      "Epoch 84/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0248\n",
      "Epoch 85/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0248\n",
      "Epoch 86/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0252\n",
      "Epoch 87/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0819\n",
      "Epoch 88/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0301\n",
      "Epoch 89/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0254\n",
      "Epoch 90/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0245\n",
      "Epoch 91/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0241\n",
      "Epoch 92/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0240\n",
      "Epoch 93/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0244\n",
      "Epoch 94/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0246\n",
      "Epoch 95/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0250\n",
      "Epoch 96/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0248\n",
      "Epoch 97/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0244\n",
      "Epoch 98/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0425\n",
      "Epoch 99/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0240\n",
      "Epoch 100/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0235\n",
      "Epoch 101/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0237\n",
      "Epoch 102/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0236\n",
      "Epoch 103/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0240\n",
      "Epoch 104/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0241\n",
      "Epoch 105/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0538\n",
      "Epoch 106/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0243\n",
      "Epoch 107/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0235\n",
      "Epoch 108/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0233\n",
      "Epoch 109/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0234\n",
      "Epoch 110/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0234\n",
      "Epoch 111/500\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.0237\n",
      "Epoch 112/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0239\n",
      "Epoch 113/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0242\n",
      "Epoch 114/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0247\n",
      "Epoch 115/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0329\n",
      "Epoch 116/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0237\n",
      "Epoch 117/500\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.0231\n",
      "Epoch 118/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0230\n",
      "Epoch 119/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0232\n",
      "Epoch 120/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0233\n",
      "Epoch 121/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0233\n",
      "Epoch 122/500\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.0238\n",
      "Epoch 123/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0235\n",
      "Epoch 124/500\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.0764\n",
      "Epoch 125/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0260\n",
      "Epoch 126/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0237\n",
      "Epoch 127/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0231\n",
      "Epoch 128/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0229\n",
      "Epoch 129/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0229\n",
      "Epoch 130/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0227\n",
      "Epoch 131/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0229\n",
      "Epoch 132/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0236\n",
      "Epoch 133/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0230\n",
      "Epoch 134/500\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.0241\n",
      "Epoch 135/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0231\n",
      "Epoch 136/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0235\n",
      "Epoch 137/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0236\n",
      "Epoch 138/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0232\n",
      "Epoch 139/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0284\n",
      "Epoch 140/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1945\n",
      "Epoch 141/500\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.0379\n",
      "Epoch 142/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0324\n",
      "Epoch 143/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0305\n",
      "Epoch 144/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0290\n",
      "Epoch 145/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0279\n",
      "Epoch 146/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0275\n",
      "Epoch 147/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0268\n",
      "Epoch 148/500\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.0267\n",
      "Epoch 149/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0275\n",
      "Epoch 150/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0250\n",
      "Epoch 151/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0271\n",
      "Epoch 152/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0249\n",
      "Epoch 153/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0244\n",
      "Epoch 154/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0261\n",
      "Epoch 155/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0247\n",
      "Epoch 156/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0254\n",
      "Epoch 157/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0278\n",
      "Epoch 158/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0254\n",
      "Epoch 159/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0239\n",
      "Epoch 160/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0241\n",
      "Epoch 161/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0241\n",
      "Epoch 162/500\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.0244\n",
      "Epoch 163/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0247\n",
      "Epoch 164/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0252\n",
      "Epoch 165/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0239\n",
      "Epoch 166/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0239\n",
      "Epoch 167/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0251\n",
      "Epoch 168/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0239\n",
      "Epoch 169/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0235\n",
      "Epoch 170/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0238\n",
      "Epoch 171/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0240\n",
      "Epoch 172/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0236\n",
      "Epoch 173/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0239\n",
      "Epoch 174/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0608\n",
      "Epoch 175/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0250\n",
      "Epoch 176/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0234\n",
      "Epoch 177/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0230\n",
      "Epoch 178/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0229\n",
      "Epoch 179/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0230\n",
      "Epoch 180/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0231\n",
      "Epoch 181/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0228\n",
      "Epoch 182/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0230\n",
      "Epoch 183/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0233\n",
      "Epoch 184/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0227\n",
      "Epoch 185/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0238\n",
      "Epoch 186/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0229\n",
      "Epoch 187/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0229\n",
      "Epoch 188/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0230\n",
      "Epoch 189/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0228\n",
      "Epoch 190/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0343\n",
      "Epoch 191/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0228\n",
      "Epoch 192/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0222\n",
      "Epoch 193/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0221\n",
      "Epoch 194/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0221\n",
      "Epoch 195/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0228\n",
      "Epoch 196/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0225\n",
      "Epoch 197/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0226\n",
      "Epoch 198/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0226\n",
      "Epoch 199/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0236\n",
      "Epoch 200/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0223\n",
      "Epoch 201/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0232\n",
      "Epoch 202/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0225\n",
      "Epoch 203/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0267\n",
      "Epoch 204/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0220\n",
      "Epoch 205/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0220\n",
      "Epoch 206/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0220\n",
      "Epoch 207/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0227\n",
      "Epoch 208/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0227\n",
      "Epoch 209/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0222\n",
      "Epoch 210/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0225\n",
      "Epoch 211/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0221\n",
      "Epoch 212/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0222\n",
      "Epoch 213/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0225\n",
      "Epoch 214/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0221\n",
      "Epoch 215/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0236\n",
      "Epoch 216/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0218\n",
      "Epoch 217/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0221\n",
      "Epoch 218/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0231\n",
      "Epoch 219/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0217\n",
      "Epoch 220/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0218\n",
      "Epoch 221/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0222\n",
      "Epoch 222/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0216\n",
      "Epoch 223/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0217\n",
      "Epoch 224/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0253\n",
      "Epoch 225/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0218\n",
      "Epoch 226/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0210\n",
      "Epoch 227/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0211\n",
      "Epoch 228/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0216\n",
      "Epoch 229/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0218\n",
      "Epoch 230/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0218\n",
      "Epoch 231/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0221\n",
      "Epoch 232/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0211\n",
      "Epoch 233/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0219\n",
      "Epoch 234/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0215\n",
      "Epoch 235/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0219\n",
      "Epoch 236/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0212\n",
      "Epoch 237/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0215\n",
      "Epoch 238/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0214\n",
      "Epoch 239/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0280\n",
      "Epoch 240/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 241/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 242/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0206\n",
      "Epoch 243/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0208\n",
      "Epoch 244/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0214\n",
      "Epoch 245/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0211\n",
      "Epoch 246/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0209\n",
      "Epoch 247/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0217\n",
      "Epoch 248/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0210\n",
      "Epoch 249/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0207\n",
      "Epoch 250/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0241\n",
      "Epoch 251/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 252/500\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 253/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0209\n",
      "Epoch 254/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0219\n",
      "Epoch 255/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0209\n",
      "Epoch 256/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0212\n",
      "Epoch 257/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0210\n",
      "Epoch 258/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0212\n",
      "Epoch 259/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0239\n",
      "Epoch 260/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0229\n",
      "Epoch 261/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0200\n",
      "Epoch 262/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0200\n",
      "Epoch 263/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 264/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 265/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0209\n",
      "Epoch 266/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0207\n",
      "Epoch 267/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0202\n",
      "Epoch 268/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0208\n",
      "Epoch 269/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0208\n",
      "Epoch 270/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0207\n",
      "Epoch 271/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0207\n",
      "Epoch 272/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0208\n",
      "Epoch 273/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0202\n",
      "Epoch 274/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0210\n",
      "Epoch 275/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0210\n",
      "Epoch 276/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0218\n",
      "Epoch 277/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0206\n",
      "Epoch 278/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0206\n",
      "Epoch 279/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 280/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0258\n",
      "Epoch 281/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 282/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0196\n",
      "Epoch 283/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0195\n",
      "Epoch 284/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 285/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0200\n",
      "Epoch 286/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0204\n",
      "Epoch 287/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0202\n",
      "Epoch 288/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0202\n",
      "Epoch 289/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0202\n",
      "Epoch 290/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0199\n",
      "Epoch 291/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0203\n",
      "Epoch 292/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0204\n",
      "Epoch 293/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0200\n",
      "Epoch 294/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0203\n",
      "Epoch 295/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0293\n",
      "Epoch 296/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0196\n",
      "Epoch 297/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 298/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 299/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 300/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 301/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 302/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 303/500\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.0195\n",
      "Epoch 304/500\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.0200\n",
      "Epoch 305/500\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.0204\n",
      "Epoch 306/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 307/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0202\n",
      "Epoch 308/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0198\n",
      "Epoch 309/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 310/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0204\n",
      "Epoch 311/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0196\n",
      "Epoch 312/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 313/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0196\n",
      "Epoch 314/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0232\n",
      "Epoch 315/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 316/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 317/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 318/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 319/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 320/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0198\n",
      "Epoch 321/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0199\n",
      "Epoch 322/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0199\n",
      "Epoch 323/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0202\n",
      "Epoch 324/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0195\n",
      "Epoch 325/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0198\n",
      "Epoch 326/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0194\n",
      "Epoch 327/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 328/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 329/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0195\n",
      "Epoch 330/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 331/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0259\n",
      "Epoch 332/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 333/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 334/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 335/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 336/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0189\n",
      "Epoch 337/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 338/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 339/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 340/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0196\n",
      "Epoch 341/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0195\n",
      "Epoch 342/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 343/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 344/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 345/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 346/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 347/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0194\n",
      "Epoch 348/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0221\n",
      "Epoch 349/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 350/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 351/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 352/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 353/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 354/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 355/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 356/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 357/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0202\n",
      "Epoch 358/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 359/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 360/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 361/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 362/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 363/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 364/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 365/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 366/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 367/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 368/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 369/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 370/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0207\n",
      "Epoch 371/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0182\n",
      "Epoch 372/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 373/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 374/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 375/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0189\n",
      "Epoch 376/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 377/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0189\n",
      "Epoch 378/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 379/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 380/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 381/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 382/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 383/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 384/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 385/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 386/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 387/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0198\n",
      "Epoch 388/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 389/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0181\n",
      "Epoch 390/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 391/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 392/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 393/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 394/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 395/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 396/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0181\n",
      "Epoch 397/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 398/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 399/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 400/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 401/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 402/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 403/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 404/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 405/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 406/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 407/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 408/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 409/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 410/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 411/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0181\n",
      "Epoch 412/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 413/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 414/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0181\n",
      "Epoch 415/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 416/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 417/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 418/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0182\n",
      "Epoch 419/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0189\n",
      "Epoch 420/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 421/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0182\n",
      "Epoch 422/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 423/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 424/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 425/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 426/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0182\n",
      "Epoch 427/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 428/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 429/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0199\n",
      "Epoch 430/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 431/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 432/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 433/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 434/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0175\n",
      "Epoch 435/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 436/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 437/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 438/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 439/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 440/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 441/500\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 442/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0182\n",
      "Epoch 443/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 444/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 445/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0170\n",
      "Epoch 446/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 447/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 448/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 449/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 450/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 451/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 452/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0175\n",
      "Epoch 453/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 454/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 455/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 456/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 457/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0175\n",
      "Epoch 458/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 459/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 460/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 461/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 462/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 463/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0170\n",
      "Epoch 464/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 465/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 466/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0170\n",
      "Epoch 467/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 468/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 469/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 470/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 471/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 472/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 473/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 474/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 475/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 476/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 477/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 478/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 479/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0169\n",
      "Epoch 480/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 481/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 482/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 483/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 484/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0170\n",
      "Epoch 485/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 486/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 487/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 488/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 489/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 490/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 491/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 492/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 493/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 494/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 495/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 496/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 497/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 498/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 499/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0169\n",
      "Epoch 500/500\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.0167\n"
     ]
    }
   ],
   "source": [
    "autoencoder_train = autoencoder.fit(X_train, Y_train, batch_size=5,epochs=500,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 117ms/step - loss: 0.3458\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.3109\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.1335\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.1156\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.1112\n",
      "Epoch 6/100\n",
      " 7/11 [==================>...........] - ETA: 0s - loss: 0.1154"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-90e50dd0c0d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m autoencoder_train = autoencoder.fit_generator(aug.flow(X_train, Y_train, batch_size=10),\n\u001b[0;32m----> 6\u001b[0;31m                                               steps_per_epoch=len(X_train) // 10 ,epochs=100,verbose=1)\n\u001b[0m",
      "\u001b[0;32m/home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p287103/anaconda3/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.25,\n",
    "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "autoencoder_train = autoencoder.fit_generator(aug.flow(X_train, Y_train, batch_size=10),\n",
    "                                              steps_per_epoch=len(X_train) // 10 ,epochs=100,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8f16efee9459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m118\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ind=8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "ind=np.random.randint(118)\n",
    "print(ind)\n",
    "# ind=8\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15,4))\n",
    "\n",
    "im=imvec[ind]\n",
    "label=labelvec[ind]\n",
    "# print(label)\n",
    "# plt.subplots(2,4 ,4)\n",
    "print(label.sum())\n",
    "plt.subplot(1, 5,1)\n",
    "plt.imshow(im)\n",
    "\n",
    "val = filters.threshold_otsu(im)\n",
    "im3=im[:,:,1]>val\n",
    "plt.subplot(1, 5,2)\n",
    "\n",
    "plt.imshow(im3)\n",
    "l = measure.label(im3)\n",
    "print(l.max())\n",
    "\n",
    "\n",
    "plt.subplot(1, 5,3)\n",
    "plt.imshow(label)\n",
    "# X_test = np.reshape(im,(-1,150, 270, 1))\n",
    "X_test = np.reshape(im,(-1,x, y, inChannel))\n",
    "# X_test = np.reshape(im,(-1,43, 78, 1))\n",
    "# X_test = np.reshape(im,(1,28, 140))\n",
    "\n",
    "# preds = loaded_model.predict(X_test)\n",
    "preds = autoencoder.predict(X_test)\n",
    "print(preds.shape)\n",
    "pred=np.reshape(preds,(x, y))\n",
    "plt.subplot(1, 5,4)\n",
    "plt.imshow(pred)\n",
    "print(pred.sum())\n",
    "io.imsave('1.jpg',pred)\n",
    "val = filters.threshold_sauvola(label)\n",
    "drops = ndimage.binary_opening(label)\n",
    "l = measure.label(drops)\n",
    "print(l.max())\n",
    "# pred=preds[:,:,1]\n",
    "# plt.imshow(p)\n",
    "pred=io.imread('1.jpg')\n",
    "plt.subplot(1, 5,5)\n",
    "\n",
    "val = filters.threshold_otsu(pred)\n",
    "# drops = ndimage.binary_fill_holes(pred<val )\n",
    "im2=pred>val\n",
    "plt.imshow(im2, cmap='gray')\n",
    "drops = ndimage.binary_closing(pred )\n",
    "l = measure.label(im2)\n",
    "print(l.max())\n",
    "histo=ndimage.measurements.histogram(pred,0,1,256)\n",
    "# print(histo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(autoencoder, open('final_prediction.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import flask\n",
    "from flask import Flask\n",
    "from flask import Flask, request, redirect, url_for, flash, jsonify\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
